
https://blog.csdn.net/qq_32447301/article/details/90321610
-----------------------------------------------------------------


shuffle write：分区数由上一阶段的RDD分区数控制
类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则，临时存放到各个executor所在的本地磁盘上。
shuffle read：分区数由Spark提供的参数控制
如果这个参数值设置的很小，同时shuffle read量很大，那么单个task处理的数据量也会很大，这可能导致JVM crash，从而获取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。
有时候即使不会导致JVM crash也会造成长时间的gc。

修改Hive/SQL表注释:
ALTER TABLE table_name SET TBLPROPERTIES('comment' = '这是表注释!');
修改Hive/SQL字段注释:
ALTER TABLE table_name CHANGE COLUMN muid muid_new STRING COMMENT '这里是列注释!'; 


mysql回滚(表引擎必须是INNODB) 可以show create table xx;查看
select * from table_name;
回滚事务步骤:
start transaction;   开始事务
savepoint a;   创建保存点a
delete from table_name where id = 1;  删除一条记录
select * from table_name;
rollback to a;  回滚到a保存点
select * from table_name;  没问题的话  执行commit;


https://www.cnblogs.com/rainwang/p/7213918.html    GC分析   G1  不研究CMS


PYSPARK_DRIVER_PYTHON=ipython $SPARK_HOME/bin/pyspark


--------------------------------------
写博客   distinct去重和group by去重

https://blog.csdn.net/hd243608836/article/details/80088173


https://www.2cto.com/database/201707/662371.html


https://blog.csdn.net/jerrytomcat/article/details/82351605


-------------------------------------------

