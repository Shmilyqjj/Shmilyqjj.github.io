shuffle write：分区数由上一阶段的RDD分区数控制
类似于saveAsLocalDiskFile的操作，将计算的中间结果按某种规则，临时存放到各个executor所在的本地磁盘上。
shuffle read：分区数由Spark提供的参数控制
如果这个参数值设置的很小，同时shuffle read量很大，那么单个task处理的数据量也会很大，这可能导致JVM crash，从而获取shuffle数据失败，同时executor也丢失了，看到Failed to connect to host的错误，也就是executor lost的意思。
有时候即使不会导致JVM crash也会造成长时间的gc。

修改Hive/SQL表注释:
ALTER TABLE table_name SET TBLPROPERTIES('comment' = '这是表注释!');
修改Hive/SQL字段注释:
ALTER TABLE table_name CHANGE COLUMN muid muid_new STRING COMMENT '这里是列注释!'; 


PYSPARK_DRIVER_PYTHON=ipython $SPARK_HOME/bin/pyspark














*************************************待写博客****************************************
--------------------------------Mysql Binlog---------------------------------
mysql回滚(表引擎必须是INNODB) 可以show create table xx;查看
select * from table_name;
回滚事务步骤:
start transaction;   开始事务
savepoint a;   创建保存点a
delete from table_name where id = 1;  删除一条记录
select * from table_name;
rollback to a;  回滚到a保存点
select * from table_name;  没问题的话  执行commit;
-----------------------------------------------------------------------------


--------------------------------JVM GC分析--------------------------------
https://www.cnblogs.com/rainwang/p/7213918.html    GC分析   G1  不研究CMS
-------------------------------------------------------------------------
