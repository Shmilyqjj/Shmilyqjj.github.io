---
title: 线程进程与锁
author: 佳境
avatar: >-
  https://cdn.jsdelivr.net/gh/Shmilyqjj/Shmily-Web@master/cdn_sources/img/custom/avatar.jpg
authorLink: shmily-qjj.top
authorAbout: 你自以为的极限，只是别人的起点
authorDesc: 你自以为的极限，只是别人的起点
categories:
  - 技术
comments: true
tags:
  - 线程、进程
  - 概念
keywords: 线程进程与锁
photos: >-
  https://cdn.jsdelivr.net/gh/Shmilyqjj/Shmily-Web@master/cdn_sources/Blog_Images/JAVA/ThreadAndLock/ThreadAndLock-cover.jpg
abbrlink: 6f97dc89
date: 2020-02-11 11:20:08
description:
---

# 线程进程与锁  
线程，进程与锁是一定要掌握的基础知识点，希望能通过写博客的方式加深印象，并且在以后能够随时补充和回看。  
## 进程  
### 概念  

1.什么是进程  
进程是**可并发执行的程序在某个数据集合上的一次计算活动**，也是**操作系统进行资源分配和调度的基本单位**。

2.进程的特征  
动态性：进程是程序的执行，同时进程有生命周期。  
并发性：多个进程可同存于内存中，能在一段时间内同时执行。  
独立性：资源分配和调度的基本单位。  
制约性：并发进程间存在制约关系，造成程序执行速度不可预测性，必须对进程的并发执行次序、相对执行速度加以协调。  
结构特征：进程由程序块 、数据块、进程控制块三部分组成。  

3.进程的三种基本状态  
运行态：当进程得到处理机，其执行程序正在处理机上运行时的状态称为运行状态。  
就绪态：当一个进程已经准备就绪，一旦得到CPU，就可立即运行，这时进程所处的状态称为就绪状态。
阻塞态：若一个进程正等待着某一事件发生(如等待输入输出操作的完成)而暂时停止执行的状态称为等待状态。处于等待状态的进程不具备运行的条件，即使给它CPU，也无法执行。系统中有几个等待进程队列（按等待的事件组成相应的等待队列）。  

运行到等待：等待某事件的发生（如等待I/O完成）
等待到就绪：事件已经发生（如I/O完成）
运行到就绪：时间片到（例如，两节课时间到，下课）或出现更高优先级进程，当前进程被迫让出处理器。
就绪到运行：当处理机空闭时，由调度（分派）程序从就绪进程队列中选择一个进程占用CPU。

## 线程  
### 概念  
1.什么是线程  
线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

2.线程与进程的关系  
 * 进程是**系统资源分配**的基本单位-线程是**任务调度执行**的基本单位  
 * 进程**切换开销大**-**线程间切换开销小**  
 * 进程间**资源和地址空间独立**-同一进程下线程**共享资源和地址空间**
 * 进程崩溃不影响其他进程-线程崩溃整个进程都崩溃**（多进程健壮性强）**
 
3.线程间共享的资源  
 * 线程间共享**堆**和**方法区**  
 * **虚拟机栈**、**本地方法栈**、**程序计数器**不共享  
 * 为什么程序计数器资源不共享：程序计数器不共享是为了**线程切换后能恢复到正确的执行位置**  
 * 为什么虚拟机栈和本地方法栈私有：栈帧用于存储局部变量表、操作数栈、常量池引用等信息，而本地方法栈则为虚拟机使用到的Native方法服务，两者相似。为了**保证局部变量不被其他线程访问**，所以不共享。  
 * 为什么堆和方法区共享：新创建的对象存放在堆中，类信息、常量、静态变量、即时编译器编译后的代码存放在方法区。  
 * 多线程不一定提高效率，只是让CPU利用率更高，如果频繁切换可能效率反而更低。  

4.线程间通信方式  
 * 全局变量  
 * 线程上下文  
 * 共享内存
 * 套接字Socket  
 * IPC通信
 如何实现线程间通讯：1.通过类变量直接将数据放到主存中 2.通过并发的数据结构来存储数据 3.使用volatile变量或者锁 4.调用atomic类 
 
5.进程间通信方式  
 * 管道
 * 有名管道
 * 信号量
 * 共享内存
 * 消息队列
 * 信号
 * 套接字
 
### 线程池
 * 为什么要用线程池？
    频繁创建和销毁线程费时低效而且浪费内存(线程死亡，相关对象变成垃圾)。线程池尽可能减少了对象创建和销毁的次数，让线程运行完不立即销毁，而是重复使用，从而提高效率。  
    
 * ThreadPoolExecutor是线程池的核心类，构造参数的意义：
    ```
    corePoolSize：核心线程池的大小，如果核心线程池有空闲位置，这是新的任务就会被核心线程池新建一个线程执行，执行完毕后不会销毁线程，线程会进入缓存队列等待再次被运行。
 
    maximunPoolSize：线程池能创建最大的线程数量。如果核心线程池和缓存队列都已经满了，新的任务进来就会创建新的线程来执行。但是数量不能超过maximunPoolSize，否侧会采取拒绝接受任务策略。
 
    keepAliveTime：非核心线程能够空闲的最长时间，超过时间，线程终止。这个参数默认只有在线程数量超过核心线程池大小时才会起作用。只要线程数量不超过核心线程大小，就不会起作用。
   
    unit：时间单位，和keepAliveTime配合使用。

    workQueue：缓存队列，用来存放等待被执行的任务。

    threadFactory：线程工厂，用来创建线程，一般有三种选择策略。
        ArrayBlockingQueue;
        LinkedBlockingQueue;
        SynchronousQueue;
   
    handler：拒绝处理策略，线程数量大于最大线程数就会采用拒绝处理策略，四种策略为
        ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 
        ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 
        ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
        ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 
         
    ThreadPoolExecutor还有两个常用的方法shutdown和submit，两者都用来关闭线程池，但是后者有一个结果返回。
    ```
   
 * 常见线程池
 **newCachedThreadPool**：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。  
    * 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。
      
    * 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。  
    
    * 适用大量耗时较少的线程任务
    
 **newFixedThreadPool**：创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。  
    * 线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。
    
 **newSingleThreadExecutor**：单线程串行执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。
    * 单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。
    
 **newScheduleThreadPool**：创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。
    * 该线程池多用于执行延迟任务或者固定周期的任务。
 

## 锁  
### 分类  
1.**公平锁和非公平锁**：公平锁指多个线程按照申请锁的顺序排队来依次获取锁。非公平锁是没有顺序获取锁。
2.**可重入锁**：又名递归锁，是指同一个线程在外层的方法获取到了锁，在进入内层方法会自动获取到锁。
3.**共享锁S和排它锁X**：多个线程可以同时获取一个共享锁，一个共享锁可被多个线程拥有。排它锁也叫独占锁，同一时刻只能被统一线程占用，其他线程需要等待。
4.**互斥锁和读写锁**：一次只能有一个线程拥有互斥锁，读写锁多个读者可同时读，写必须互斥。写优先于读，如果有写，读必须等待。
5.**乐观锁和悲观锁**：乐观锁认为读取数据时其他线程不会对数据做修改，不加锁，更新数据时采用尝试更新不断重试的方式。悲观锁认为读取数据时其他线程会对数据做修改，会出问题，所以默认加锁。
6.**分段锁**：提升并发程序性能的手段之一，粒度更小。将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。所以说，ConcurrentHashMap在并发情况下，不仅保证了线程安全，而且提高了性能。
7.**偏向锁、轻量级锁、重量级锁**：偏向锁是减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。重量级锁，其他线程试图获取锁时，都会被阻塞，只有持有锁的线程释放锁之后才会唤醒这些线程，进行竞争。
   无锁状态->偏向锁状态->轻量级锁状态->重量级锁状态 随竞争情况逐渐升级 不可逆   后续会在**[概念](https://shmily-qjj.top/6f97dc89/#%E6%A6%82%E5%BF%B5-2)**部分详细说
   ![alt ThreadAndLock-01](https://cdn.jsdelivr.net/gh/Shmilyqjj/Shmily-Web@master/cdn_sources/Blog_Images/JAVA/ThreadAndLock/ThreadAndLock-01.JPG)  
   偏向锁：仅有一个线程进入临界区
   轻量级锁：多个线程交替进入临界区
   重量级锁：多个线程同时进入临界区
   
8.**自旋锁**：线程没获得锁时不会被挂起而是空循环，可以减少线程阻塞造成的线程切换的概率。首先，阻塞或唤醒Java线程需要操作系统切换CPU状态来完成，状态切换耗费CPU，可能切换CPU的时间比同步代码块中代码的执行时间都要长，为了很短的同步锁定时间而花费很长的线程切换时间是不值得的，如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。  
8.**自适应自旋锁**：自适应是值虚拟机会记录一个锁对象自旋时间和状态，如果之前自旋等待成功获得锁，这次自旋也很大概率成功，会允许持续更长时间的自选等待，后面的自旋会大概率拿到锁。如果一个对象的锁自旋等待很少能成功获取到锁，后续减少自旋次数甚至忽略自旋过程，直接阻塞，避免浪费CPU资源。
11.**读写锁**：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写。

### 概念

1.从底层角度看，本质上只有一个关键字和两个接口：Synchronized和Lock接口以及ReadWriteLock接口（读写锁）

2.synchronize与reentrantLock  
```
synchronize是一个隐式的重入锁，比较笨重，实现方式是锁主存和缓存一致性。
reentrantLock是一个显式的重入锁，比较灵活，可以扩展为分段锁，实现方式是AQS。
```

3.synchronize和Lock：
```
  1、synchronize是java内置关键字，而Lock是一个类。
  2、synchronize可以作用于变量、方法、代码块，而Lock是显式地指定开始和结束位置。
  3、synchronize不需要手动解锁，当线程抛出异常的时候，会自动释放锁；而Lock则需要手动释放，所以lock.unlock()需要放在finally中去执行。
  4、性能方面，如果竞争不激烈的时候，synchronize和Lock的性能差不多，如果竞争激烈的时候，Lock的效率会比synchronize高。
  5、Lock可以知道是否已经获得锁，synchronize不能知道。Lock扩展了一些其他功能如让等待的锁中断、知道是否获得锁等功能，Lock 可以提高效率。
  6、synchronize是悲观锁的实现，而Lock则是乐观锁的实现，采用的CAS的尝试机制。
```

4.synchronize和ReenTrantLock：
```
  除开上面和Lock的区别，还有一些区别：
  1、ReenTrantLock可以中断锁的等待，提供了一些高级功能。
  2、多个线程在等待的时候，可以提供公平的锁，默认的是非公平锁，性能会比公平锁好一些。
  3、ReenTrantLock可以绑定多个锁条件。
```

5.无锁、偏向锁、轻量级锁、重量级锁及升级过程  

6.锁消除：  
```
先说“逃逸分析技术”，该技术在编译期使用，分析对象的动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。  
该技术将确定不会发生逃逸的对象放入栈内存而非堆(故不是所有对象都在堆中)。
为了减少锁的请求和释放操作，“逃逸分析技术”在编译期分析出那些本来不存在竞争却加了锁的代码，让他们的锁失效，从而达到减少锁的请求和释放的目的。
```

7.锁偏向：  
```
先说一下Java对象头，它包括Mark Words、Klass Words两部分，可能还包括数组的长度（如果对象是个数组）。
Klass Word里面存的是一个地址，占32位或64位，是一个指向当前对象所属于的类的地址，可以通过这个地址获取到它的元数据信息。
Mark Word！重点，这里面主要包含对象的哈希值、年龄分代、锁标志位等，大小为32位或64位。锁状态不同时MarkWord里内容会不同。
锁偏向：当第一个线程请求时，会判断锁的对象头里的ThreadId字段的值，如果为空，则让该线程持有偏向锁，并将ThreadId的值置为当前线程ID。当前线程再次进入时，如果线程ID与ThreadId的值相等，则该线程就不会再重复获取锁了。因为锁的请求与释放是要消耗系统资源的。
如果有其他线程也来请求该锁，则偏向锁就会撤销，然后升级为轻量级锁。如果锁的竞争十分激烈，则轻量级锁又会升级为重量级锁。
```

8.锁粗化：  
在编译期间将相邻的同步代码块合并成一个大同步块。这样做可以减少反复申请和释放同一个锁对象导致的系统开销。



### 死锁
1.什么是死锁  
两个或多个线程互相持有对方需要的资源，导致一直等待状态，互相等待对方释放资源，如果没有主动释放资源，就会死锁。

2.死锁产生条件   
   1、存在循环等待
   2、存在资源竞争
   3、已经获得的资源不会被剥夺
   4、请求与保持，一个线程因请求资源被阻塞时，拥有资源的线程的状态不会改变。

3.避免死锁
    产生死锁条件中任意一条不满足，就不会产生死锁

4.死锁定位修复
    执行程序时，程序没停止，也不继续运行，则是死锁
    通过jps获取端口号，再jstack工具可以看到


### 其他
关于AQS和CAS详细：https://www.jianshu.com/p/2a48778871a9


